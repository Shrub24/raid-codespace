{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LiteLLM - Exercise\n",
        "\n",
        "Complete the exercises below by filling in the TODO sections. Run each cell to test your code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import litellm \n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "# Load .env file for non-codespace users\n",
        "load_dotenv()\n",
        "OLLAMA_MODEL = f\"ollama_chat/{os.environ['OLLAMA_MODEL']}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1a: Basic Message\n",
        "Create a message asking the AI a question of your choice, then call the API and print the response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a messages list with your question\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"...\"} # Replace ... with your question\n",
        "]\n",
        "\n",
        "# TODO: Make a completion call with gemini/gemini-2.5-flash\n",
        "response = None  # Your code here\n",
        "\n",
        "# TODO: Print the response content\n",
        "pass  # Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1b: Local Model\n",
        "Make the same request using the local OLLAMA_MODEL instead.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Call the same messages with OLLAMA_MODEL and print the response\n",
        "pass  # Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Streaming\n",
        "Ask the AI to write a short story (2-3 sentences) and stream the response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create messages asking for a short story (pick your own theme!)\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"...\"} # Replace ... with your prompt\n",
        "]\n",
        "\n",
        "# TODO: Make a streaming completion call\n",
        "response = None  # Your code here\n",
        "\n",
        "# TODO: Loop through chunks and print them\n",
        "pass  # Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Temperature Experiment\n",
        "Ask the AI to suggest a creative name for something (your choice: a pet, band, startup, etc.) at two different temperatures.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create your message\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"...\"} # Replace ... with your prompt\n",
        "]\n",
        "\n",
        "print(\"Low temperature (0.2):\")\n",
        "# TODO: Make a call with temperature=0.2\n",
        "pass  # Your code here\n",
        "\n",
        "print(\"\\nHigh temperature (1.8):\")\n",
        "# TODO: Make a call with temperature=1.8\n",
        "pass  # Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: System Prompt - Your Choice!\n",
        "Create a system prompt that gives the AI a persona. Some ideas:\n",
        "- A Shakespearean poet\n",
        "- An excited sports commentator\n",
        "- A helpful medieval wizard\n",
        "- Your own creative idea!\n",
        "\n",
        "Then ask it a question to test the persona.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create messages with a system prompt and user question\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"...\"},  # Your system prompt here\n",
        "    {\"role\": \"user\", \"content\": \"...\"}  # Your question here\n",
        "]\n",
        "\n",
        "# TODO: Make the call and print the response\n",
        "pass  # Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 5: Building Context\n",
        "Create a 3-turn conversation where:\n",
        "1. User introduces themselves with a fact\n",
        "2. Assistant responds\n",
        "3. User asks the assistant to recall the fact from turn 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Build a 3-turn conversation\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"...\"},  # Turn 1: Your user introduction\n",
        "    {\"role\": \"assistant\", \"content\": \"...\"},  # Turn 2: Assistant response (make up a plausible response)\n",
        "    {\"role\": \"user\", \"content\": \"...\"}  # Turn 3: Your user question asking about turn 1\n",
        "]\n",
        "\n",
        "# TODO: Make the call and print the response\n",
        "pass  # Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 6: Controlling Costs\n",
        "\n",
        "Here are quick examples of cost control techniques from Lesson 1.5. Just run this cell to see how they work!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Limiting response length with max_tokens\n",
        "messages = [{\"role\": \"user\", \"content\": \"Explain quantum physics.\"}]\n",
        "\n",
        "print(\"Short response (max_tokens=50):\")\n",
        "response = litellm.completion(\n",
        "    model=\"gemini/gemini-2.5-flash\",\n",
        "    messages=messages,\n",
        "    max_tokens=50\n",
        ")\n",
        "print(response.choices[0].message.content)\n",
        "print(f\"Tokens used: {response.usage.total_tokens}\\n\")\n",
        "\n",
        "# 2. Using stop to control output\n",
        "messages = [{\"role\": \"user\", \"content\": \"List five programming languages:\"}]\n",
        "\n",
        "print(\"Stopped after 3 items:\")\n",
        "response = litellm.completion(\n",
        "    model=\"gemini/gemini-2.5-flash\",\n",
        "    messages=messages,\n",
        "    stop=[\"4.\"]\n",
        ")\n",
        "print(response.choices[0].message.content)\n",
        "print(f\"Tokens used: {response.usage.total_tokens}\\n\")\n",
        "\n",
        "# 3. Tracking costs\n",
        "messages = [{\"role\": \"user\", \"content\": \"What is AI?\"}]\n",
        "\n",
        "response = litellm.completion(\n",
        "    model=\"gemini/gemini-2.5-flash\",\n",
        "    messages=messages,\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "cost = litellm.completion_cost(completion_response=response)\n",
        "print(\"Cost tracking:\")\n",
        "print(f\"Response: {response.choices[0].message.content[:100]}...\")\n",
        "print(f\"Tokens: {response.usage.total_tokens}\")\n",
        "print(f\"Cost: ${cost:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 7: Create Your Own AI Persona\n",
        "Combine everything you've learned! Create an AI with a unique behavior using:\n",
        "- A creative system prompt\n",
        "- A few example exchanges (context)\n",
        "- An appropriate temperature\n",
        "- Streaming output\n",
        "\n",
        "Some ideas:\n",
        "- A motivational coach who speaks in movie quotes\n",
        "- A time traveler from the year 3000\n",
        "- A detective who solves mysteries in everything\n",
        "- Your own creative idea!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create your unique AI persona\n",
        "system_prompt = \"\"\"\n",
        "Your system prompt here\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    # Add example exchanges if you want\n",
        "    {\"role\": \"user\", \"content\": \"...\"}  # Add your final user message\n",
        "]\n",
        "\n",
        "# TODO: Make a streaming call with appropriate temperature\n",
        "pass  # Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus Challenge: Multi-Turn Conversation Loop\n",
        "Create a simple chatbot that:\n",
        "1. Maintains conversation history\n",
        "2. Takes 3 user inputs\n",
        "3. Remembers context from previous turns\n",
        "\n",
        "You'll need to append messages to a list after each turn!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement a multi-turn conversation\n",
        "# Hint: Start with a system prompt, then add messages in a loop\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
        "]\n",
        "\n",
        "# TODO: Create a loop for 3 user inputs\n",
        "# For each input:\n",
        "#   1. Add user message to messages list\n",
        "#   2. Call the API\n",
        "#   3. Print the response\n",
        "#   4. Add assistant response to messages list\n",
        "\n",
        "pass  # Your code here\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
